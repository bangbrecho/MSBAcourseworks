{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DpWopaeoA1_V"
   },
   "source": [
    "# RAG as a Diabetes Question Answering\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xi526EqXA9Xi"
   },
   "source": [
    "The medical domain benefits from RAG's architecture, where precision is non-negotiable. Diabetes is one of the most active areas of clinical research. This system combines established search techniques with modern AI language models. Designed specifically for diabetes research, this approach organises information into clear summaries while maintaining links to original sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_O-d10oABYt"
   },
   "source": [
    "# 1. Initialisation and Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DHwc7AlkAHr2"
   },
   "source": [
    "Data is collected from ClinicalTrials.gov using clinical trials API. The studies are limited to 1000 studies to minimise computational cost. From the studies, NCT ID, title, and summary. NCT ID is used as metadata to connect the summary to the research ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3429,
     "status": "ok",
     "timestamp": 1748788382692,
     "user": {
      "displayName": "Basil Basil",
      "userId": "10665298970573720638"
     },
     "user_tz": -60
    },
    "id": "XIsWNvbpnF4T",
    "outputId": "fdc0744e-0c1f-48ca-e423-9dd3bc765864"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 1000 studies\n",
      "        NCT ID                                     Official Title  \\\n",
      "0  NCT05484427           Kids Diabetes Telemedicine Study (KITES)   \n",
      "1  NCT05208827  A Multicenter Randomized Controlled Study of V...   \n",
      "2  NCT04616027  A PHASE 1, OPEN-LABEL, SINGLE-DOSE, PARALLEL G...   \n",
      "3  NCT03977727  An Exploratory, Single-center, Randomized, Ope...   \n",
      "4  NCT04073927  The Butyful Study. Effect of Butyrate on Infla...   \n",
      "\n",
      "                                       Brief Summary  \n",
      "0  Randomised prospective single-center clinical ...  \n",
      "1  This study was a double-blind multicenter rand...  \n",
      "2  This study will characterize the effect of var...  \n",
      "3  This is an exploratory, single-center, randomi...  \n",
      "4  The objective is to assess the impact of 12 we...  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# API Configuration\n",
    "base_url = \"https://clinicaltrials.gov/api/v2/studies\"\n",
    "params = {\n",
    "    \"query.titles\": \"Diabetes\",\n",
    "    \"pageSize\": 100,\n",
    "    \"fields\": \"protocolSection.identificationModule.nctId,\" +\n",
    "              \"protocolSection.identificationModule.officialTitle,\" +\n",
    "              \"protocolSection.descriptionModule.briefSummary\"\n",
    "}\n",
    "\n",
    "# Data Collection\n",
    "studies = []\n",
    "max_studies = 1000  # Limit for runs to minimise computational cost. Removing the limit would increase the number of studies that the RAG learns from.\n",
    "\n",
    "while len(studies) < max_studies:\n",
    "    response = requests.get(base_url, params=params)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error: HTTP {response.status_code}\")\n",
    "        break\n",
    "\n",
    "    data = response.json()\n",
    "    new_studies = data.get('studies', [])\n",
    "\n",
    "    if not new_studies:\n",
    "        break\n",
    "\n",
    "    studies.extend(new_studies)\n",
    "\n",
    "    if len(studies) >= max_studies:\n",
    "        studies = studies[:max_studies]  # Trim in case we exceeded\n",
    "        break\n",
    "\n",
    "    if not data.get('nextPageToken'):\n",
    "        break\n",
    "\n",
    "    params['pageToken'] = data['nextPageToken']\n",
    "\n",
    "# Structured Extraction\n",
    "cleaned_data = []\n",
    "for study in studies:\n",
    "    protocol = study.get('protocolSection', {})\n",
    "    ident = protocol.get('identificationModule', {})\n",
    "    desc = protocol.get('descriptionModule', {})\n",
    "\n",
    "    cleaned_data.append({\n",
    "        \"NCT ID\": ident.get('nctId'), # Getting the NCT ID\n",
    "        \"Official Title\": ident.get('officialTitle'), # Getting the Title\n",
    "        \"Brief Summary\": desc.get('briefSummary') # Getting the summary\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(cleaned_data)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"diabetes_trials_summaries.csv\", index=False)\n",
    "\n",
    "print(f\"Retrieved {len(studies)} studies\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M36woxa2fsD6"
   },
   "source": [
    "# 2. Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BcE4lRgeBO3K"
   },
   "source": [
    "This code transforms raw clinical trial data into structured documents, with page content having the title and summary of the clinical trial and the NCT ID as a metadata. This approach achieves document retrieval that is still connected to its ID, crucial for medical research questioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UjBch8Ddoutl"
   },
   "outputs": [],
   "source": [
    "# Example LangChain Document creation\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=f\"Title: {item['Official Title']}\\nSummary: {item['Brief Summary']}\",\n",
    "        metadata={\"source\": item['NCT ID']}\n",
    "    )\n",
    "    for item in cleaned_data\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZBwAeeSDI7g"
   },
   "source": [
    "## 2.1 Enhanced Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WfSlvy5AH8cg"
   },
   "source": [
    "This system implements a multi-stage retrieval pipeline to maximize precision and recall when searching diabetes clinical trials. By combining keyword-based retrieval (BM25) with semantic search (neural embeddings) and cross-encoder re-ranking, it addresses key challenges in medical information retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9QNs8Hh7JOLE"
   },
   "source": [
    "### 2.1.1 Keyword-based Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kXv89yDXJYEJ"
   },
   "source": [
    "rank_bm25 library is used for exact term matching, prioritizing documents containing explicit query terms. This part ensures high precision for protocol-specific queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rXN0WUmMUrCQ"
   },
   "outputs": [],
   "source": [
    "!pip install -q rank_bm25\n",
    "!pip install -q nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5498,
     "status": "ok",
     "timestamp": 1748788417626,
     "user": {
      "displayName": "Basil Basil",
      "userId": "10665298970573720638"
     },
     "user_tz": -60
    },
    "id": "ZMj9AnUuUsRv",
    "outputId": "009e5660-3a3d-4506-d82b-307e096fb0f4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')  # Needed for BM25 tokenization\n",
    "from nltk.tokenize import word_tokenize\n",
    "from rank_bm25 import BM25Okapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lx7bKwD7UzeZ"
   },
   "outputs": [],
   "source": [
    "# Build BM25 index\n",
    "bm25_corpus = [word_tokenize(doc.page_content.lower()) for doc in docs]\n",
    "bm25 = BM25Okapi(bm25_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 106540,
     "status": "ok",
     "timestamp": 1748788539414,
     "user": {
      "displayName": "Basil Basil",
      "userId": "10665298970573720638"
     },
     "user_tz": -60
    },
    "id": "KwdYIFXSd3Q6",
    "outputId": "ac844310-ead8-4f8e-8a50-d2a5c552fb25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m90.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "im1g1K_zMNHw"
   },
   "source": [
    "### 2.1.2 Cross Encoder Reranker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WrQGE05JMR9i"
   },
   "source": [
    "ms-marco-MiniLM-L-6-v2 is used to refine retrieved documents. It scores relevance based on full query-document interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296,
     "referenced_widgets": [
      "bd0ee1cdae3a461e9bad23273593883a",
      "6d9a01e1ba964ef7940fa2f7e0ca658d",
      "afa1153743de4ce58a5aab93160bb957",
      "b6a81eb04dd64559be3db6d6d51eac91",
      "68921769229c4d0fa967b0ad63585dbc",
      "3dfd73d2141d45b6a7a17c19e1349a55",
      "2d8344ee2d57446181372b250943c3e2",
      "3300e25ec5fb460e82671801033798a8",
      "b6e6fe41930340daaf0c49d773591ec4",
      "90c9957ccdf042de8d4c4553ca05109c",
      "18f493e3459445deb9dea2484d3b54c4",
      "78e41e784582430f853d355075dab0d2",
      "e80badb9229641d6b64cc4476f1b4e83",
      "dc1ef103b6704e60afc2bb48c8ed7207",
      "d922a739cae849b7b86c356881b78433",
      "78d3990dc08c4137bee6d4be4089a001",
      "9a6ce6c4d0794ef08eff63e1a59bedcd",
      "39d47b90859c47cbbe0f8280a739a747",
      "11e0374b9f1741e98a75263ae109d450",
      "e0cc6ff6ca9f4a89a0167bd881ca3cc9",
      "7a6bbf2151f54340a1dbd9bf621d7afc",
      "f5e2f7baf9e44ecd8d4a2a247715abe8",
      "e9b059147d994b919192fab1cd6cbefa",
      "1c86af2e7f3e439bb4a9833164a9e897",
      "972a8f80436c47ce8da0354fad354725",
      "e8f43883f505433da16eb0de8ac0821f",
      "5c6f1e3b23274c33ba8dfcae293ca9dd",
      "61b4e413631945308b538e25d366978a",
      "1969e55be0b74f9d874c9be7ef5dc3ae",
      "07657c6a253349d9a4223a05b0c45bd2",
      "3e0dff9e68ac4b1ba90e753353f390a7",
      "b3eaf32618f54fdca6764ed12bf92d3d",
      "642a31e48f634708b0f70f305bbed6b4",
      "8355574eac9244919c809794b50017ef",
      "866d8b62e446454e998664ad54fb0e6f",
      "e003b9f125154aa0ac7718a138354131",
      "2df9de773a814e038c9ee43f481c160a",
      "ef351a74f97641d09839b7cb19718c56",
      "774e30b7330444fea127a822e9f0a5bb",
      "0dd85935f22042d68a421409e74a619a",
      "c8ae3e5e220d49de9cded04e586093d4",
      "879cdbfc3d5344a3a4ce11ed6e1f02db",
      "9b572e39f62b4953a79ee26e6e3f3c88",
      "e85eaee289ff4215954f2adca98b5cce",
      "34f077a191cc41679190d7f6aef63947",
      "defaa731a6d347a2a2e043d3a8d02c88",
      "5050012de30f4d6f9edaa9e3fd57bf7c",
      "630d326054824943bb4ab819d548bd12",
      "c460bba7b6cb4008b69fa942d35693bb",
      "139740f5dabd499a8ce96057c4334c58",
      "ec8693d0239a44429a7ea23826e36add",
      "e9bdfb6d7a424bf78453bf2fba0f0702",
      "65c0ac04c28c4224bc6b7f2d79a36ec1",
      "7c7275bf0f2c409ba636ba87f2085021",
      "0a953623917a4aeba1d29463f24412b4",
      "4323f2847db948b0ba0edc6f83bc7fa5",
      "e6f246f325624f53a1b2a32aa8965dc1",
      "55b1becaf11e4eff8e9915e3fe39d02a",
      "a14068c9eacd4cfab6351dfc66118fbf",
      "06b3ae6f8ee848b5b731b21f2b125268",
      "7c0bbf523ad74302996bd41d74fbbd02",
      "f4e413b5c501493ea6416899c838f374",
      "0b942ad9ad12427588044e33d961f258",
      "9332265347014ffb97a025571520955a",
      "5d88d17b354148c790968fce7e90806a",
      "9abceb61ecef4f2cb40a80873f3ec9d8",
      "2b67b880f2d24a2abde2b18841b9ec13",
      "5cc33f15293f48a7960c531e72074b2c",
      "17e6852bc3114c419a384fdcd8a5c645",
      "dd420f5e2b814738b3a9907fef7f948b",
      "c4bce72a93c14b94a1331174ff7555f6",
      "f312c16bd5b9431eb0461ec185d42721",
      "8311b69c6e824a8fb09a86f07b00c81a",
      "84ec36c52026485f8ccab9d354ed1c92",
      "a6cd2519f04f4ccaa1ae019c01f315c1",
      "af61086fddd94ede856b0564a1635d99",
      "95e8e43b647d4267aad22ba894e31bd1"
     ]
    },
    "executionInfo": {
     "elapsed": 36198,
     "status": "ok",
     "timestamp": 1748788656820,
     "user": {
      "displayName": "Basil Basil",
      "userId": "10665298970573720638"
     },
     "user_tz": -60
    },
    "id": "YB9B68Cpd4Ew",
    "outputId": "6c35d868-a2b0-41c1-d548-ddcab50bd402"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd0ee1cdae3a461e9bad23273593883a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78e41e784582430f853d355075dab0d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9b059147d994b919192fab1cd6cbefa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.33k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8355574eac9244919c809794b50017ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34f077a191cc41679190d7f6aef63947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4323f2847db948b0ba0edc6f83bc7fa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b67b880f2d24a2abde2b18841b9ec13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.66k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "# Load a cross-encoder model (good default for re-ranking)\n",
    "reranker = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UAzBcGE6NtKa"
   },
   "source": [
    "### 2.1.3 Hybrid Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6kWPx7-DOkDu"
   },
   "source": [
    "Hybrid retrieval combines dense result with BM25 and reranks it using cross-encoder. This approach will make the code be able to retrieve specific wording and also different wording with the same semantic meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yWL2-wbSU0cP"
   },
   "outputs": [],
   "source": [
    "def hybrid_retrieval(query, k=5, rerank_top_n=5):\n",
    "    # Dense results (FAISS)\n",
    "    retriever_dense = vectorstore.as_retriever(search_kwargs={\"k\": k})\n",
    "    dense_results = retriever_dense.invoke(query)\n",
    "\n",
    "    # Sparse results (BM25)\n",
    "    tokenized_query = word_tokenize(query.lower())\n",
    "    sparse_scores = bm25.get_scores(tokenized_query)\n",
    "    top_sparse = sorted(enumerate(sparse_scores), key=lambda x: x[1], reverse=True)[:k]\n",
    "    sparse_results = [docs[i] for i, _ in top_sparse]\n",
    "\n",
    "    # Combine and deduplicate by source\n",
    "    combined_docs = {doc.metadata[\"source\"]: doc for doc in (dense_results + sparse_results)}\n",
    "    combined_list = list(combined_docs.values())\n",
    "\n",
    "    # Re-rank using cross-encoder\n",
    "    pairs = [(query, doc.page_content) for doc in combined_list]\n",
    "    scores = reranker.predict(pairs)\n",
    "\n",
    "    # Sort by relevance\n",
    "    ranked = sorted(zip(combined_list, scores), key=lambda x: x[1], reverse=True)\n",
    "    top_docs = [doc for doc, _ in ranked[:rerank_top_n]]\n",
    "    return top_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lL72RFZV3Xxm"
   },
   "source": [
    "### 2.1.4 Step-back Question\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VHiPMlRs3os-"
   },
   "source": [
    "Step back questioning reformulates the prompt into a higher order question, emulating reasoning patterns of humans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fvl_cDsQI9_f"
   },
   "outputs": [],
   "source": [
    "def generate_step_back_question(question: str, client) -> str:\n",
    "    \"\"\"Converts specific medical questions to conceptual ones\"\"\"\n",
    "    step_back_prompt = \"\"\"Analyze this medical question and extract its core physiological or clinical concept:\n",
    "\n",
    "    Original Question: {question}\n",
    "\n",
    "    Guidelines:\n",
    "    1. Identify the overarching biological system\n",
    "    2. Remove specific drug names or trial references\n",
    "    3. Focus on mechanisms or principles\n",
    "\n",
    "    Step-Back Question:\"\"\"\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=MODEL,\n",
    "        contents=step_back_prompt.format(question=question)\n",
    "    )\n",
    "    return response.text.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Zb3iuY64Q8G"
   },
   "source": [
    "## 2.2 Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K6_YHLEn4UmF"
   },
   "source": [
    "verification step to ensure factual consistency of the response with the retrieved evidence, it asks the model to determine whether each factual claim in the answer can be substantiated by the cited clinical trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0M5ae7-yGRTp"
   },
   "outputs": [],
   "source": [
    "def verify_medical_answer(answer: str, context: str, client) -> tuple[bool, str]:\n",
    "    \"\"\"Checks answer against context\"\"\"\n",
    "    verification_prompt = \"\"\"Verify this medical answer:\n",
    "\n",
    "    Answer: {answer}\n",
    "    Context: {context}\n",
    "\n",
    "    Rules:\n",
    "    1. Return \"TRUE\" only if ALL claims are supported\n",
    "    2. Return \"FALSE: [reason]\" otherwise\n",
    "\n",
    "    Judgment:\"\"\"\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=MODEL,\n",
    "        contents=verification_prompt.format(answer=answer, context=context)\n",
    "    )\n",
    "    return (\"TRUE\" in response.text), response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 7202,
     "status": "ok",
     "timestamp": 1748788679406,
     "user": {
      "displayName": "Basil Basil",
      "userId": "10665298970573720638"
     },
     "user_tz": -60
    },
    "id": "fnvP8F9yuhm6",
    "outputId": "90108be0-f7b1-4e2c-d7ed-3887770a10fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.24-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.59 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.60)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.25)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.42)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (0.3.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (2.11.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (4.13.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.4.26)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.59->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (2.33.2)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
      "Downloading langchain_community-0.3.24-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
      "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.24 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.9.1 python-dotenv-1.1.0 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jRcHZIRo4oEL"
   },
   "source": [
    "# 3. Vector Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eU4ERlDQ4wTl"
   },
   "source": [
    "The embedded representations are indexed and stored using the chroma vector database. The vector store is populated by embedding the full set of retrieved documents and persisting for future reuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458,
     "referenced_widgets": [
      "97852b7a772e44c9ad8702bb18e5c91a",
      "12c3f4a21bf7408c9e5fac634b0ea8b7",
      "6f64cd986c384596a52f5c3e21b85d2a",
      "953844954c5c4f848a87c1d0057dbd99",
      "42c6c285a8bd44ac9aa1860677557be1",
      "1bd1b6291b774d15a8320b519cc05bb0",
      "a5f540f82ddf492e909534d8e0189f7c",
      "842ee2efb7b048b58f9a52f67a0e7282",
      "8532edcbb0f94210a592bc574fdbec93",
      "9e810866861947778a8ff1138e0a0b9a",
      "2290f7ce641f410cbf83cb120f3a80b1",
      "0e65dfeff0314844a020fa55fbe9436d",
      "72fc3fb1b74f401b8b8540cab9bbe8b0",
      "b5d4486e8a364a54a80ae00264736644",
      "88fe87becb80459bacaed2774155f94b",
      "da21f696c4cf4f8da947cbbb794e250d",
      "93b3d859246641ff88f1f612d5334f22",
      "63ca235a86b347bcb63334a6acf58799",
      "2f28cb8a983b421a85439cbf217bc55c",
      "872a8b38fc8a4d9080d382c4951057f7",
      "215fa105c3824683b0aeddd368fc7696",
      "a5124c28728f45b2b6011ea34c44e68c",
      "b49c5b463f714a7090d315938c783d46",
      "52b6cb643f0a41369b49268a6bf9bceb",
      "50e2ca54919045b2afa8d1ba0bbba3ba",
      "f26d7569a2b44a94bdcad0321a0f7046",
      "06d13c3c9f5f49f79b03a0ed64aa707b",
      "ad7cd8d6982d4a62862aff738d81be69",
      "1f366fd749f44b1da85d445b086fd5d0",
      "46375b987104431aa6d091d015494af3",
      "07e852f12e284e85abdb245bfdfb3ed7",
      "25730e5424f54fa087c3fd0a3d5958cc",
      "91c318eb029a40bdb45614f21c9a1bf5",
      "6ed40cdbe50343ca88f4a6e0d308ffb3",
      "f62db65698bd4c04a08997e0768b4ea1",
      "7056d377de17458698657ef9074e9724",
      "f2c686e58e0548abb00540e079e71224",
      "9ab2da37947d498ba99ac02f051d2c89",
      "6f99fe3ba96548f39b9d87f309ccecf0",
      "2f56f305e0b64ffc9da1fd0f83d13e8f",
      "46ba84242cb44a8ead16374665a17183",
      "162ae230700246229a8fcc3e8de22b21",
      "efc91d5693294837882b2c256169b620",
      "f185da202b204b2a86c09287a42749b3",
      "d954ae2fc15c43828c909f8b1e5fc8e0",
      "b86973ab09f14778a26f65bfd05a1e6e",
      "4d77a7b855af4c81a027b7b258e92584",
      "003eab10762d4206a09cf487252e0b96",
      "52304bcaa2874927aa9095328a26245b",
      "fcb9744b24194be4b64f886fdb9f42cf",
      "c4bb50adf3ab433081d666bb334582c6",
      "aab05d7ba32e4839887b34afdc6a841a",
      "4e72b43e8b934e629cd7e341be078058",
      "5777009bc8af4365a76d91fa6a69827b",
      "dbc4281cd2f243e5ab08ce6325f0a948",
      "147e896edcf7474c83745287cf259e69",
      "b0a74798312146a7856e7725444ab394",
      "4488a4881b2e4352bf0cd8613e8ee329",
      "0708a9fd1b8b4ddc9a1c194cc4215696",
      "a08ebd08a83a4f19a21dd1a4046b8f76",
      "08f9723e93044576816f1c2c427157e9",
      "e4c42c9e1bd3432daf47dfd2c622218a",
      "7c0091c1dac7448e85f7661310cb6ca4",
      "7477b1d908034e88b95f0379017a0be2",
      "f3c84a1dc05840fea61b8c8ea5f76165",
      "9892546239ae4cb29cdbbb19bbc4b2f0",
      "a0574336558c49bfb72eeeb1ab2290b8",
      "3ac15193e483407f93327483876e6ee5",
      "3745f9e91ca34d97a7791405a4189504",
      "3536ec96d5d24973990cc5f3f8c9b05e",
      "04489fc20c804466b991f0bcd968be76",
      "6605e6b65b5c4976bca3b26acb3bf109",
      "41230553d6704759bc45bd8a3df6adb3",
      "0dc4ff05b730446ba53b2b1fe8bc1507",
      "49ec17effd764e0b9e6c8af989769ea5",
      "753ab136fed54646957fe05e1fabcadd",
      "0dcadeb9c5164e9789372f1c90b93f81",
      "54acce9d3c1449ce834eb741c59a3a0c",
      "266193e7c9004c41a9bd7aacb3826f6e",
      "42bf950050c54b53a2674a7010eb191c",
      "920806801d3f4762af8ac2ed6c580de6",
      "ab093072d0a148cc9ac27dd683d55e35",
      "3a323b645c554725a6444e894b5bd6af",
      "9da7e8ef96994fb7bef59ba21beea88b",
      "860d481949b148ffa27507d75b6a2907",
      "afa5792a21354a098ae7c1a2390a0b06",
      "790b3c4e676b4a3da0923e37b3a3d5f4",
      "b710ca1738f14061beaeaaec723b2c1e",
      "92ee2f40e5274bbc8d3307649c9f3773",
      "57715769dd394231bd557a2bbeb96083",
      "a3c92be918c54f6b97e85a6f3f50db83",
      "b7e4f39815924acfb08fcecf0f7de689",
      "892e1426a36e4ec89d1e8c72c6d773e1",
      "ac7faa90254d47c7a69965d5e007521e",
      "f8e76e3251df40d4a8dc23827e04e91e",
      "8721865a3f1b4aaa82d8443185ce0f6c",
      "e343ca2530c244d8955879c9054c728b",
      "57c333c1db69417ba22bdf5b4c35a770",
      "80166aa6ec4f498aac3af6cfbca284de",
      "7814a81e5c6e4cccb18433d2b51d0f80",
      "c3af7caa7251483a84f7161c6309daa6",
      "13703d1936bb4c4397eec6ed1c1f16a2",
      "779eb20924574750b95c69cd3b4c709f",
      "6f84858e81f54ee3a2f4b11fe4202def",
      "799f3ea0cfaa49b5bfb5197a47e86c6f",
      "092a0f8c502f48da854c291fa926a63f",
      "205c7eae39974ed7a6ac20a992cfeab3",
      "2c0a03a04c4d489f88184db56d6ff044",
      "19931567c824461095b999f16ac27d0a",
      "014debb04c124f9db39a9ce270a8e105",
      "a389fc13c2314342be4a9c482ddacbfc",
      "99a775d03fd8419db2b5b2560378771c",
      "7230dacf0afc46f48c2584f73e37e911",
      "599e8e4ad66e40e98f3bc4547ba412b3",
      "1f702f9d59794e39862465bfbf4842c2",
      "6c991645872246f492eda4b18ca2d783",
      "e2f761d604204d749d851de62690900d",
      "9fab6311c8854af4a83c2057d1983997",
      "71857c74a9bb488897668d812617dc8b",
      "1c1ff381907c4e3ca01746ac8ba2fd1c",
      "0a63d528ecb74aea946c1f9570ca4e08"
     ]
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 9504,
     "status": "ok",
     "timestamp": 1748788729958,
     "user": {
      "displayName": "Basil Basil",
      "userId": "10665298970573720638"
     },
     "user_tz": -60
    },
    "id": "L--4ERTauagV",
    "outputId": "05e2d7c2-1283-41fa-d160-324577048672"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-bbae26f46fd7>:5: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97852b7a772e44c9ad8702bb18e5c91a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e65dfeff0314844a020fa55fbe9436d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b49c5b463f714a7090d315938c783d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ed40cdbe50343ca88f4a6e0d308ffb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d954ae2fc15c43828c909f8b1e5fc8e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "147e896edcf7474c83745287cf259e69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0574336558c49bfb72eeeb1ab2290b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54acce9d3c1449ce834eb741c59a3a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92ee2f40e5274bbc8d3307649c9f3773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7814a81e5c6e4cccb18433d2b51d0f80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a389fc13c2314342be4a9c482ddacbfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# Initialize embeddings (local model)\n",
    "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 24747,
     "status": "ok",
     "timestamp": 1748788768183,
     "user": {
      "displayName": "Basil Basil",
      "userId": "10665298970573720638"
     },
     "user_tz": -60
    },
    "id": "vZk6hXbAxp7S",
    "outputId": "1514fee2-a1a8-4947-9a61-b0cd15e76bdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb\n",
      "  Downloading chromadb-1.0.12-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.11.4)\n",
      "Collecting fastapi==0.115.9 (from chromadb)\n",
      "  Downloading fastapi-0.115.9-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvicorn-0.34.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.0.2)\n",
      "Collecting posthog>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-4.2.0-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.13.2)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_api-1.33.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.33.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.54b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_sdk-1.33.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.1)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
      "Collecting overrides>=7.3.1 (from chromadb)\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.71.0)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.3)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.1.2)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.18)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.23.0)\n",
      "Collecting starlette<0.46.0,>=0.40.0 (from fastapi==0.115.9->chromadb)\n",
      "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
      "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.25.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
      "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.4.0)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.4)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting importlib-metadata<8.7.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.33.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.33.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.33.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_proto-1.33.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.54b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.54b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation==0.54b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation-0.54b1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.54b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.54b1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-util-http==0.54b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_util_http-0.54b1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.54b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.54b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.4.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.31.4)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n",
      "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.2)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Downloading chromadb-1.0.12-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.3/19.3 MB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fastapi-0.115.9-py3-none-any.whl (94 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_api-1.33.1-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.33.1-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.33.1-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.33.1-py3-none-any.whl (55 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.54b1-py3-none-any.whl (12 kB)\n",
      "Downloading opentelemetry_instrumentation-0.54b1-py3-none-any.whl (31 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.54b1-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.54b1-py3-none-any.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.9/194.9 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_util_http-0.54b1-py3-none-any.whl (7.3 kB)\n",
      "Downloading opentelemetry_sdk-1.33.1-py3-none-any.whl (118 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading posthog-4.2.0-py2.py3-none-any.whl (96 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.7/96.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvicorn-0.34.3-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
      "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m93.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (454 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=d1f1e4781f1804ccca8372d212c6df80f94472834cf71a629a9f7cb9fad82149\n",
      "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, durationpy, uvloop, uvicorn, overrides, opentelemetry-util-http, opentelemetry-proto, mmh3, importlib-metadata, humanfriendly, httptools, deprecated, bcrypt, backoff, asgiref, watchfiles, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, opentelemetry-semantic-conventions, onnxruntime, kubernetes, fastapi, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib_metadata 8.7.0\n",
      "    Uninstalling importlib_metadata-8.7.0:\n",
      "      Successfully uninstalled importlib_metadata-8.7.0\n",
      "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.3.0 chromadb-1.0.12 coloredlogs-15.0.1 deprecated-1.2.18 durationpy-0.10 fastapi-0.115.9 httptools-0.6.4 humanfriendly-10.0 importlib-metadata-8.6.1 kubernetes-32.0.1 mmh3-5.1.0 onnxruntime-1.22.0 opentelemetry-api-1.33.1 opentelemetry-exporter-otlp-proto-common-1.33.1 opentelemetry-exporter-otlp-proto-grpc-1.33.1 opentelemetry-instrumentation-0.54b1 opentelemetry-instrumentation-asgi-0.54b1 opentelemetry-instrumentation-fastapi-0.54b1 opentelemetry-proto-1.33.1 opentelemetry-sdk-1.33.1 opentelemetry-semantic-conventions-0.54b1 opentelemetry-util-http-0.54b1 overrides-7.7.0 posthog-4.2.0 pypika-0.48.9 starlette-0.45.3 uvicorn-0.34.3 uvloop-0.21.0 watchfiles-1.0.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "f68e04c02201409aa131e31b4c966581",
       "pip_warning": {
        "packages": [
         "importlib_metadata"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 91720,
     "status": "ok",
     "timestamp": 1748788886841,
     "user": {
      "displayName": "Basil Basil",
      "userId": "10665298970573720638"
     },
     "user_tz": -60
    },
    "id": "RT91VlemxhI9",
    "outputId": "e9f1b421-ce93-4c82-9c5e-f451a6a7e889"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new vector store...\n",
      "Vector store persisted to 'db'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-65ef9e93a918>:20: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectorstore.persist()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "persist_directory = \"db\"\n",
    "\n",
    "# Load existing Chroma vector store if it exists\n",
    "if os.path.exists(persist_directory) and os.listdir(persist_directory):\n",
    "    print(\"Loading existing vector store...\")\n",
    "    vectorstore = Chroma(\n",
    "        persist_directory=persist_directory,\n",
    "        embedding_function=embeddings\n",
    "    )\n",
    "else:\n",
    "    print(\"Creating new vector store...\")\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=docs,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=persist_directory\n",
    "    )\n",
    "    vectorstore.persist()\n",
    "    print(f\"Vector store persisted to '{persist_directory}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uc6qwvmL87sv"
   },
   "source": [
    "# 4. Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpWHpLyT41Wl"
   },
   "source": [
    "The generation component of the system uses Gemini 2.0 and is implemented through a controlled prompting guide. A domain specific prompt is designed to constrain the model’s behavior by defining its role and output expectations. The prompt instructs the model to generate responses that rely strictly on the retrieved clinical trial data, cite NCT identifiers when referencing studies, and organize the output into three defined sections which are summary, key findings, and limitations.This step is complete with step-back query reformulation, cross-encoder reranking, and answer verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9889,
     "status": "ok",
     "timestamp": 1748788939522,
     "user": {
      "displayName": "Basil Basil",
      "userId": "10665298970573720638"
     },
     "user_tz": -60
    },
    "id": "XxKNiqxQ89vN",
    "outputId": "7208930f-e66f-47b8-e8a7-cf3f410a9d3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/199.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m194.6/199.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.5/199.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install -q -U google-genai  # Install or update google-genai\n",
    "!pip install -q -U google-generativeai  # Install or update google-generativeai\n",
    "\n",
    "from google.colab import userdata\n",
    "from google import genai\n",
    "\n",
    "# Set your Google API key (ensure it's stored securely)\n",
    "GOOGLE_API_KEY = userdata.get('Google_API')\n",
    "client = genai.Client(api_key=GOOGLE_API_KEY)\n",
    "MODEL = \"gemini-2.0-flash\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7IGojSs1-e0v"
   },
   "outputs": [],
   "source": [
    "def answer_with_gemini(query, client):\n",
    "    \"\"\"\n",
    "    Uses hybrid retrieval (BM25 + vector + reranking) and Gemini to answer the query.\n",
    "    Additionally, performs step-back question analysis and medical answer verification.\n",
    "    \"\"\"\n",
    "    # Step 1: Generate the \"Step-Back\" version of the query\n",
    "    step_back_query = generate_step_back_question(query, client)\n",
    "    print(f\"Step-back query: {step_back_query}\")\n",
    "\n",
    "    # Step 2: Retrieve documents based on the step-back query using hybrid retrieval\n",
    "    retrieved_docs = hybrid_retrieval(step_back_query, k=8, rerank_top_n=5)\n",
    "\n",
    "    # Construct context from retrieved documents\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "    sources = [doc.metadata[\"source\"] for doc in retrieved_docs]\n",
    "\n",
    "    # Step 3: Generate an answer with Gemini based on the context\n",
    "    system_instructions = \"\"\"\n",
    "    You are a medical AI assistant. Follow these rules:\n",
    "    1. Base answers ONLY on the provided clinical trial data.\n",
    "    2. Cite NCT IDs (e.g., NCT0123456) when referencing trials.\n",
    "    3. If unsure, say \"This requires medical expertise.\"\n",
    "    4. Structure responses:\n",
    "       - Summary of relevant trials\n",
    "       - Key findings\n",
    "       - Limitations\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"{system_instructions}\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Question:\n",
    "    {query}\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 4: Generate the answer with Gemini\n",
    "    response = client.models.generate_content(\n",
    "        model=MODEL,\n",
    "        contents=prompt\n",
    "    )\n",
    "\n",
    "    # Step 5: Verify the generated medical answer against the context\n",
    "    answer = response.text\n",
    "    is_verified, verification_message = verify_medical_answer(answer, context, client)\n",
    "\n",
    "    if is_verified:\n",
    "        print(\"Answer Verified: TRUE\")\n",
    "    else:\n",
    "        print(f\"Answer Verified: FALSE. Reason: {verification_message}\")\n",
    "\n",
    "    # Return the generated answer and sources\n",
    "    return answer, sources\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KomGcr66qbF5"
   },
   "source": [
    "# 5. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YLI6LN8r6Z04"
   },
   "source": [
    "This internal evaluation is the model's evaluation mechanism to evaluate the RAG's answer using Gemini 2.0 LLM. Using LLM, the code evaluates the answer based on the faithfulness, factuality, completeness, fluency, and citation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bYiq6oAEqea6"
   },
   "outputs": [],
   "source": [
    "def evaluate_generation(query, answer, context, client):\n",
    "    \"\"\"\n",
    "    Evaluates the quality of a generated medical answer using Gemini.\n",
    "    Returns the raw evaluation output as text.\n",
    "    \"\"\"\n",
    "    evaluation_prompt = f\"\"\"\n",
    "You are a medical evaluation assistant.\n",
    "\n",
    "Evaluate the quality of the answer generated for the following clinical question based only on the retrieved context.\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Context (retrieved trials):\n",
    "{context}\n",
    "\n",
    "Generated Answer:\n",
    "{answer}\n",
    "\n",
    "Score each from 0 to 2:\n",
    "1. Faithfulness: Does the answer stay within the information found in the context?\n",
    "2. Factuality: Are all claims medically accurate?\n",
    "3. Completeness: Does the answer fully address the question?\n",
    "4. Fluency: Is the answer well-written and easy to understand?\n",
    "5. Proper Citation: Are clinical trial references (e.g., NCT IDs) correctly cited?\n",
    "\n",
    "Respond ONLY in JSON format:\n",
    "{{\n",
    "  \"faithfulness\": <0|1|2>,\n",
    "  \"factuality\": <0|1|2>,\n",
    "  \"completeness\": <0|1|2>,\n",
    "  \"fluency\": <0|1|2>,\n",
    "  \"citations\": <0|1|2>\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    eval_response = client.models.generate_content(\n",
    "        model=MODEL,\n",
    "        contents=evaluation_prompt\n",
    "    )\n",
    "\n",
    "    eval_text = eval_response.text\n",
    "    print(\"Evaluation output:\\n\", eval_text)\n",
    "    return eval_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QTr6Zmsq0rTN"
   },
   "source": [
    "# 6. Querying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nya4cPfZ5e4J"
   },
   "source": [
    "## 6.1. Query 1: What is diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q3HeX5Ob6w4E"
   },
   "source": [
    "Query 1 asks the fundamental question what is diabetes to ask the RAG model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7178,
     "status": "ok",
     "timestamp": 1748803901838,
     "user": {
      "displayName": "Basil Basil",
      "userId": "10665298970573720638"
     },
     "user_tz": -60
    },
    "id": "p4aOXfrm0x4R",
    "outputId": "eb62260b-6114-4e0e-97de-4293b57a9bcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step-back query: Step-Back Question: How does the body regulate blood glucose, and what happens when this regulation fails?\n",
      "Answer Verified: TRUE\n",
      "Answer: Based on the provided clinical trial data:\n",
      "\n",
      "*   **Type 1 Diabetes (T1D):** This is characterized by the loss of pancreatic beta cells, leading to a lack of endogenous insulin production (Effects of SGLT-2 Inhibitor Dapagliflozin on Hormonal Glucose Regulation and Ketogenesis in Patients With Type 1 Diabetes - a Randomised, Placebo-controlled, Open-label, Cross-over Intervention Study). Individuals with T1D often have a defect in glucagon secretion, increasing the risk of hypoglycemia (Can Maximising Time in Range Using Automated Insulin Delivery and a Low Carbohydrate Diet Restore the Glucagon Response to Hypoglycaemic in Type 1 Diabetes?).\n",
      "*   **Type 2 Diabetes:** This is associated with hyperglycemia, which is a risk factor for cardiovascular issues (Blood Glucose Homeostasis in Type 2 Diabetes: the Effects of Saccharose).\n",
      "*   **Gestational Diabetes:** This occurs during pregnancy and may require drug therapies like insulin or glyburide to control blood sugar (Pilot Study of Exenatide Pharmacokinetics and Pharmacodynamics in Gestational Diabetes).\n",
      "\n",
      "['NCT04614168', 'NCT04035031', 'NCT01905020', 'NCT00821665', 'NCT05482789']\n"
     ]
    }
   ],
   "source": [
    "user_question = \"what is diabetes?\" #@param {type:\"string\"}\n",
    "answer, sources = answer_with_gemini(user_question, client)\n",
    "print(f\"Answer: {answer}\")\n",
    "print(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 995,
     "status": "ok",
     "timestamp": 1748803911183,
     "user": {
      "displayName": "Basil Basil",
      "userId": "10665298970573720638"
     },
     "user_tz": -60
    },
    "id": "vnmzUXKt1An4",
    "outputId": "eed2f011-d911-48f3-bd35-eec9956fb78b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation output:\n",
      " ```json\n",
      "{\n",
      "  \"faithfulness\": 2,\n",
      "  \"factuality\": 2,\n",
      "  \"completeness\": 1,\n",
      "  \"fluency\": 2,\n",
      "  \"citations\": 1\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "def get_context_from_sources(sources, docs):\n",
    "    # docs is your original docs list from retrieval\n",
    "    # This function joins content of docs matching the sources list\n",
    "    selected_docs = [doc for doc in docs if doc.metadata[\"source\"] in sources]\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in selected_docs])\n",
    "\n",
    "# Example usage:\n",
    "context_for_eval = get_context_from_sources(sources, docs)\n",
    "\n",
    "eval_result = evaluate_generation(user_question, answer, context_for_eval, client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2067,
     "status": "ok",
     "timestamp": 1748804002022,
     "user": {
      "displayName": "Basil Basil",
      "userId": "10665298970573720638"
     },
     "user_tz": -60
    },
    "id": "uAF13wM-1Hkk",
    "outputId": "931ef5af-2648-47ff-b8b9-1b33354d353b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini's direct answer: Diabetes is a chronic metabolic disorder characterized by elevated levels of blood glucose (or blood sugar), which leads over time to serious damage to the heart, blood vessels, eyes, kidneys, and nerves. This high blood sugar occurs because either:\n",
      "\n",
      "*   **The pancreas does not produce enough insulin:** Insulin is a hormone that regulates blood sugar.\n",
      "*   **The body cannot effectively use the insulin it produces:** This is known as insulin resistance.\n",
      "\n",
      "There are several types of diabetes, including:\n",
      "\n",
      "*   **Type 1 diabetes:** An autoimmune reaction where the body attacks and destroys insulin-producing cells in the pancreas. People with type 1 diabetes need to take insulin daily to survive.\n",
      "*   **Type 2 diabetes:** The most common type, where the body becomes resistant to insulin or doesn't produce enough insulin. Often linked to lifestyle factors like being overweight and inactive.\n",
      "*   **Gestational diabetes:** Develops during pregnancy and usually disappears after the baby is born. However, it increases the risk of developing type 2 diabetes later in life.\n",
      "\n",
      "In simple terms, diabetes is a condition where your body has trouble regulating blood sugar, leading to high blood sugar levels. This can happen because your body doesn't make enough insulin or because your body can't use insulin properly.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prompt: query with gemini LLM without using the RAG pipeline\n",
    "\n",
    "user_question = \"what is diabetes?\"\n",
    "\n",
    "prompt_text = f\"\"\"\n",
    "Answer the following question.\n",
    "Question: {user_question}\n",
    "\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL,\n",
    "    contents=prompt_text\n",
    ")\n",
    "\n",
    "print(f\"Gemini's direct answer: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Z30Te5o0wxm"
   },
   "source": [
    "## 6.2. Query 2: What is GLP-1 and why are GLP-1 agonist effective?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "87l7LC_56-HR"
   },
   "source": [
    "Query 2 asks a more indepth question about a specific hormone and medication about diabetes to the RAG model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9800,
     "status": "ok",
     "timestamp": 1748804848326,
     "user": {
      "displayName": "Basil Basil",
      "userId": "10665298970573720638"
     },
     "user_tz": -60
    },
    "id": "jo2o_9AU4b_Q",
    "outputId": "05255311-8fac-400f-d65a-4782eb135046"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step-back query: **Step-Back Question:**\n",
      "\n",
      "How do naturally occurring incretin hormones influence glucose regulation, and what mechanisms underlie the therapeutic benefit of enhancing their effects?\n",
      "Answer Verified: TRUE\n",
      "Answer: Based on the provided clinical trial data:\n",
      "\n",
      "*   **What is GLP-1?**\n",
      "\n",
      "    GLP-1 (Glucagon-like peptide-1) is an incretin hormone (NCT05826353, Title: Effects of SGLT-2 Inhibitor Dapagliflozin on Hormonal Glucose Regulation and Ketogenesis in Patients With Type 1 Diabetes - a Randomised, Placebo-controlled, Open-label, Cross-over Intervention Study). Incretins are gut peptides secreted in response to meals that enhance insulin secretion (Title: Mechanisms of Diabetes Control After Weight Loss Surgery).\n",
      "*   **Why are GLP-1 agonists effective?**\n",
      "\n",
      "    The data suggests that GLP-1 agonists are effective because they can suppress glucagon (NCT05826353, Title: Effects of SGLT-2 Inhibitor Dapagliflozin on Hormonal Glucose Regulation and Ketogenesis in Patients With Type 1 Diabetes - a Randomised, Placebo-controlled, Open-label, Cross-over Intervention Study).\n",
      "    Secretion of incretins improves after gastric bypass, possibly due to the specific anatomical changes after this surgery. (Title: Mechanisms of Diabetes Control After Weight Loss Surgery)\n",
      "\n",
      "**Limitations:**\n",
      "\n",
      "*   The provided information is limited and does not fully explain the mechanisms of action of GLP-1 agonists.\n",
      "*   The data does not explain the effects of GLP-1 on hepatic insulin sensitivity, rate of appearance of exogenous glucose and changes in incretin hormone concentrations. (Title: Effects of Colesevelam HCl on Hepatic Insulin Sensitivity, Gluconeogenesis, Glucose Absorption and Lipid Synthesis in Subjects With Type 2 Diabetes Mellitus)\n",
      "\n",
      "['NCT02550548', 'NCT04035031', 'NCT00638573', 'NCT00571220', 'NCT00596427']\n"
     ]
    }
   ],
   "source": [
    "user_question = \"what is GLP1 and why are GLP1 agonists effective?\" #@param {type:\"string\"}\n",
    "answer, sources = answer_with_gemini(user_question, client)\n",
    "print(f\"Answer: {answer}\")\n",
    "print(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 939,
     "status": "ok",
     "timestamp": 1748804940980,
     "user": {
      "displayName": "Basil Basil",
      "userId": "10665298970573720638"
     },
     "user_tz": -60
    },
    "id": "IYhHBrFd5YyI",
    "outputId": "f40fbaad-5f2e-44b0-c0e2-ceddadc06b32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation output:\n",
      " ```json\n",
      "{\n",
      "  \"faithfulness\": 2,\n",
      "  \"factuality\": 2,\n",
      "  \"completeness\": 1,\n",
      "  \"fluency\": 2,\n",
      "  \"citations\": 1\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "\n",
    "context_for_eval = get_context_from_sources(sources, docs)\n",
    "\n",
    "eval_result = evaluate_generation(user_question, answer, context_for_eval, client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5049,
     "status": "ok",
     "timestamp": 1748804972248,
     "user": {
      "displayName": "Basil Basil",
      "userId": "10665298970573720638"
     },
     "user_tz": -60
    },
    "id": "JMPZFfj45b0H",
    "outputId": "f0f4c6fe-e5c6-4a2c-bacb-c577614f0db1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini's direct answer: ## GLP-1 and GLP-1 Agonists Explained\n",
      "\n",
      "**What is GLP-1?**\n",
      "\n",
      "GLP-1 stands for **Glucagon-Like Peptide-1**. It is an **incretin hormone** naturally produced in the small intestine in response to food intake, especially after meals containing carbohydrates and fat.  Think of it as a signal your gut sends to your pancreas and brain after you eat, helping to regulate blood sugar and appetite.\n",
      "\n",
      "Here's a breakdown of GLP-1's key functions:\n",
      "\n",
      "*   **Stimulates Insulin Release:**  It prompts the pancreas to release insulin in a glucose-dependent manner.  This means insulin is released *only* when blood sugar levels are elevated. This reduces the risk of hypoglycemia (low blood sugar).\n",
      "*   **Suppresses Glucagon Secretion:**  Glucagon is a hormone that raises blood sugar. GLP-1 inhibits glucagon release, further helping to lower blood glucose levels.\n",
      "*   **Slows Gastric Emptying:**  It slows down the rate at which food empties from the stomach into the small intestine. This helps prevent rapid spikes in blood sugar after meals and can contribute to a feeling of fullness.\n",
      "*   **Reduces Appetite:** GLP-1 signals the brain to reduce appetite and increase satiety (feeling full). This can lead to reduced food intake and weight loss.\n",
      "*   **May have other potential benefits:** Some research suggests potential benefits related to cardiovascular health and neuroprotection, but more studies are needed.\n",
      "\n",
      "**Why are GLP-1 Agonists Effective?**\n",
      "\n",
      "GLP-1 agonists are **synthetic drugs that mimic the action of natural GLP-1**.  They are designed to bind to and activate the GLP-1 receptor, just like the body's own GLP-1. However, natural GLP-1 has a very short half-life (it's quickly broken down in the body). GLP-1 agonists are engineered to be longer-lasting, providing sustained activation of the GLP-1 receptor.\n",
      "\n",
      "They are effective for several reasons:\n",
      "\n",
      "*   **Improved Blood Sugar Control:** By stimulating insulin release (only when glucose is high) and suppressing glucagon, they help lower blood sugar levels effectively, especially in people with type 2 diabetes.  This leads to better glycemic control (HbA1c reduction).\n",
      "*   **Weight Loss:** The appetite-suppressing effects and slowed gastric emptying contribute significantly to weight loss. Patients tend to eat less and feel fuller for longer.  This is a key factor in their popularity for weight management.\n",
      "*   **Lower Risk of Hypoglycemia:** Because insulin release is glucose-dependent, the risk of hypoglycemia (low blood sugar) is lower compared to some other diabetes medications like sulfonylureas.\n",
      "*   **Cardiovascular Benefits:** Some GLP-1 agonists have been shown in clinical trials to reduce the risk of cardiovascular events (like heart attack and stroke) in patients with type 2 diabetes.\n",
      "*   **Convenience:** GLP-1 agonists are available in various formulations, including daily and weekly injections, and oral medications.\n",
      "\n",
      "**In summary:** GLP-1 agonists essentially amplify and extend the effects of the natural GLP-1 hormone. By improving blood sugar control, promoting weight loss, and potentially offering cardiovascular benefits, they have become a valuable tool in the management of type 2 diabetes and obesity.\n",
      "\n",
      "**Important Note:** While generally safe and effective, GLP-1 agonists can have side effects, such as nausea, vomiting, diarrhea, and constipation.  They are not suitable for everyone, and it's essential to consult with a healthcare professional to determine if they are the right treatment option. Also, some individuals may not experience the same degree of weight loss or blood sugar control.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prompt: query with gemini LLM without using the RAG pipeline\n",
    "\n",
    "user_question = \"what is GLP1 and why are GLP1 agonists effective?\"\n",
    "\n",
    "prompt_text = f\"\"\"\n",
    "Answer the following question.\n",
    "Question: {user_question}\n",
    "\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL,\n",
    "    contents=prompt_text\n",
    ")\n",
    "\n",
    "print(f\"Gemini's direct answer: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GnJylaY64aoq"
   },
   "source": [
    "## 6.3. Query 3:how is RAG different to standard LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ys-mr_87GrO"
   },
   "source": [
    "Query 3 deliberately asks a question that is not part of clinical trial nor is it about diabetes to review how the model would react."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9734,
     "status": "ok",
     "timestamp": 1748806240304,
     "user": {
      "displayName": "Basil Basil",
      "userId": "10665298970573720638"
     },
     "user_tz": -60
    },
    "id": "ywh0Ff329Vgk",
    "outputId": "3dc483a1-00e0-4f17-dc0c-394b0387c652"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step-back query: Okay, here's an analysis of the medical question, following the provided guidelines:\n",
      "\n",
      "**Original Question: how is RAG different to standard LLM?**\n",
      "\n",
      "**1. Identify the overarching biological system:**\n",
      "\n",
      "While the question *mentions* \"RAG\" and \"LLM,\" these are **computational concepts** (Retrieval-Augmented Generation and Large Language Model, respectively).  In the context of a medical *application* they become tools, or methods to do something, rather than being inherently part of a biological system. The question implicitly refers to **information processing** in a *clinical* context, and how the models being inquired about go about the task.\n",
      "\n",
      "**2. Remove specific drug names or trial references:**\n",
      "\n",
      "The original question already doesn't contain any specific drug names or trial references.\n",
      "\n",
      "**3. Focus on mechanisms or principles:**\n",
      "\n",
      "Instead of the *names* of the technologies, focus on the core *processes* and *principles* they represent.  Instead of asking about the specific technology, ask about what they *do*, and how they *do* it.\n",
      "\n",
      "**Step-Back Question:**\n",
      "\n",
      "**How does an information retrieval-enhanced system differ in its method of knowledge access and utilization from a system that relies primarily on its pre-existing training data to generate outputs in a medical context?**\n",
      "Answer Verified: TRUE\n",
      "Answer: This question is not answerable from the provided clinical trial data.\n",
      "\n",
      "['NCT06448182', 'NCT04692220', 'NCT06659744', 'NCT00121966', 'NCT05901831']\n"
     ]
    }
   ],
   "source": [
    "user_question = \"how is RAG different to standard LLM?\" #@param {type:\"string\"}\n",
    "answer, sources = answer_with_gemini(user_question, client)\n",
    "print(f\"Answer: {answer}\")\n",
    "print(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4398,
     "status": "ok",
     "timestamp": 1748806322008,
     "user": {
      "displayName": "Basil Basil",
      "userId": "10665298970573720638"
     },
     "user_tz": -60
    },
    "id": "1i5ryFiz-kos",
    "outputId": "642edcee-b2d8-4648-caf1-2b8e5450a1ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini's direct answer: RAG (Retrieval-Augmented Generation) differs from a standard LLM (Large Language Model) in a crucial way: **RAG incorporates external knowledge retrieval into the generation process, whereas a standard LLM relies solely on the knowledge it learned during its training phase.**\n",
      "\n",
      "Here's a breakdown of the key differences:\n",
      "\n",
      "*   **Knowledge Source:**\n",
      "    *   **Standard LLM:**  Its knowledge is entirely based on the massive dataset it was trained on. It can only answer questions or generate text based on what it has seen and learned from this training data.  If the information is not in its training data, it might hallucinate, make assumptions, or simply say it doesn't know.\n",
      "    *   **RAG:** It leverages an external knowledge base (e.g., a database, a collection of documents, a website index).  When a question is asked, RAG first *retrieves* relevant information from this external source, *augments* the prompt with this retrieved context, and *generates* its response.\n",
      "\n",
      "*   **Process:**\n",
      "    *   **Standard LLM:** User prompt -> LLM -> Response\n",
      "    *   **RAG:** User prompt -> Retrieval Module -> Relevant Context ->  LLM + Context -> Response\n",
      "\n",
      "*   **Strengths:**\n",
      "    *   **Standard LLM:**\n",
      "        *   Excellent at creative text generation, summarization, translation based on its learned patterns.\n",
      "        *   Fast inference speed (once trained).\n",
      "    *   **RAG:**\n",
      "        *   **Up-to-date information:** Can access the latest information from the external knowledge base, avoiding reliance on outdated training data.\n",
      "        *   **Improved accuracy:** Grounding its responses in retrieved evidence reduces hallucinations and inaccuracies.\n",
      "        *   **Explainability/Attribution:**  The retrieved context allows you to understand *why* the model gave a particular answer, as you can see the source it used.  Provides traceability.\n",
      "        *   **Domain Specificity:**  Can be tailored to specific domains by indexing a relevant knowledge base, without retraining the entire LLM.\n",
      "        *   **Reduced Hallucinations:** By providing the model with context from a trusted source, RAG helps it to generate more accurate and truthful responses and greatly reduces the occurance of hallucination.\n",
      "\n",
      "*   **Weaknesses:**\n",
      "    *   **Standard LLM:**\n",
      "        *   Prone to hallucinations (making up information).\n",
      "        *   Limited to the knowledge it was trained on; struggles with new or constantly changing information.\n",
      "        *   Difficult to update knowledge without retraining the entire model.\n",
      "    *   **RAG:**\n",
      "        *   Increased complexity:  Requires managing an external knowledge base and implementing a retrieval mechanism.\n",
      "        *   Performance depends on the quality of the retrieval mechanism.  Irrelevant or poorly retrieved context can negatively impact the response.\n",
      "        *   Can be slower than a standard LLM due to the retrieval step.\n",
      "        *   Requires careful engineering of the retrieval pipeline.\n",
      "\n",
      "**In essence:** Think of a standard LLM as a student who relies solely on what they learned in school. RAG is like a student who can also access and consult a vast library to supplement their existing knowledge, allowing them to answer questions more accurately and with more current information.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prompt: query with gemini LLM without using the RAG pipeline\n",
    "\n",
    "user_question = \"how is RAG different to standard LLM?\"\n",
    "\n",
    "prompt_text = f\"\"\"\n",
    "Answer the following question.\n",
    "Question: {user_question}\n",
    "\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL,\n",
    "    contents=prompt_text\n",
    ")\n",
    "\n",
    "print(f\"Gemini's direct answer: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKJS4DHQt-G3"
   },
   "source": [
    "# Repo upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42101,
     "status": "ok",
     "timestamp": 1752141261285,
     "user": {
      "displayName": "Basil Basil",
      "userId": "10665298970573720638"
     },
     "user_tz": -60
    },
    "id": "SsgwKdT9t9W5",
    "outputId": "2431b3a2-f91b-442c-adec-ba9ac11f2a70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "Enter your GitHub Personal Access Token: ··········\n",
      "Cloning into 'MSBAcourseworks'...\n",
      "remote: Enumerating objects: 7, done.\u001b[K\n",
      "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
      "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
      "remote: Total 7 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (7/7), 35.30 KiB | 3.92 MiB/s, done.\n",
      "cp: cannot stat '/content/drive/My Drive/RAG.ipynb': No such file or directory\n",
      "fatal: pathspec 'RAG.ipynb' did not match any files\n",
      "On branch main\n",
      "Your branch is up to date with 'origin/main'.\n",
      "\n",
      "nothing to commit, working tree clean\n",
      "Everything up-to-date\n",
      "✅ Notebook successfully pushed to your private repo!\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Replace path below with your actual notebook path inside Drive\n",
    "notebook_path_in_drive = \"/content/drive/My Drive/RAG.ipynb\"\n",
    "\n",
    "# Your existing script\n",
    "github_key = getpass('Enter your GitHub Personal Access Token: ')\n",
    "username = \"bangbrecho\"\n",
    "repo = \"MSBAcourseworks\"\n",
    "branch = \"main\"\n",
    "email = \"baspradrach@gmail.com\"\n",
    "\n",
    "!git config --global user.email \"{email}\"\n",
    "!git config --global user.name \"{username}\"\n",
    "\n",
    "!git clone https://{github_key}@github.com/{username}/{repo}.git\n",
    "\n",
    "!cp \"{notebook_path_in_drive}\" \"{repo}/\"\n",
    "\n",
    "import os\n",
    "os.chdir(repo)\n",
    "!git add \"RAG.ipynb\"\n",
    "!git commit -m \"Upload RAG.ipynb from Colab\"\n",
    "!git push origin {branch}\n",
    "\n",
    "print(\"✅ Notebook successfully pushed to your private repo!\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOP0NVO4a1jDToe6AezqnXz",
   "collapsed_sections": [
    "CDHSaQf9g6ug"
   ],
   "provenance": [
    {
     "file_id": "1cYnSGIxSEYmtGg8aZN263darkUb80Nq5",
     "timestamp": 1752142026979
    },
    {
     "file_id": "1aO6yEeBYDshZokFVyZoj0zLMIhaZgRHl",
     "timestamp": 1748556470246
    },
    {
     "file_id": "1icbe1VVSYYid6aroYMPlOH8_VjxoDVmp",
     "timestamp": 1748529304124
    },
    {
     "file_id": "11LmuSoSVT3sDvImCAUU0gpiPfYPwR0Py",
     "timestamp": 1748512932004
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
